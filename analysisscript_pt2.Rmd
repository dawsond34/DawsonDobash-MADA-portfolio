---
title: "Nausea/Bodt Temperature: Cross-Validation, ROC-Auc, and RMSE"
author: "Dawson Dobash"
date: "10/19/2021"
output: html_document
---

For this exercise, we will be using tidymodels but we will be evaluating models we create with the **Nausea/Body Temperature: Model Fitting using Tidymodels** tab. When evaluating the models, we used cross-validation, ROC-AUC, and RMSE.

To find the full analysis on this data set, click on [this link](https://github.com/dawsond34/DawsonDobash-MADA-analysis3) and it will take you to my github repository.


## Data Preparation

We will be reading in the same data cleaned from the processing script and all of the packages needed.

```{r reading data and packages}
library(here)
library(tidymodels)
library(dplyr)

#path to data
data_location <- here::here("files" ,"processeddata.rds")

#load data. 
data <- readRDS(data_location)
```

Next we will split up the data into two called the training and test where the training data will be used to create the model and the test will be to use/implement the data to see how well the model fits the data. 

```{r splitting data}
#This is splitting the data using a proportion of 1/4 test and 3/4 training
split_data <- initial_split(data, prop = 3/4)

#This is assigning acutal data sets to the ones that were made
training <- training(split_data)
test  <- testing(split_data)
```

## Workflow creation and Fitting for Full Model

Once we have our two data sets, we can now apply the recipe function to create a model from our categorical outcome with all predictors. Then we will create a logistic model for this recipe. This will all be applied to a workflow(). This workflow will be used to create a fit object for the model specified in the recipe.

```{r recipe making and workflow}
#Creating the recipe for nausea
Nausea_recipe = recipe(Nausea ~ ., data = data)

#making a path for the logistic regression models
log_mod <- logistic_reg() %>% set_engine("glm")

#Creating a workflow that adds the model type and the recipe I previously made
Nausea_wrkflow <- workflow() %>% add_model(log_mod) %>% add_recipe(Nausea_recipe)

#Creating a fit object
Nausea_fit <- Nausea_wrkflow %>% fit(data = training)

#Looking at the details of this fitted model
Nausea_fit %>% extract_fit_parsnip() %>% tidy()
```

## Evaluating Model

Now that we have a fitted object, we will apply it to the test data and predict some values.

```{r}
#We are predicting the values from the test data set with our fitted model
predict(Nausea_fit, test)

#This is also doing the same thing as the predict function but it is showing the prediction proportions at each observation
Nausea_aug1 = augment(Nausea_fit, test)
```

Now that we have some predicted values, we can use the ROC and ROC_AUC to see how well the model fits the data.

```{r roc}
#Fitting a roc curve and looking at the roc-auc to determine if the model is a good fit.

#Using the test data set
Nausea_aug1 %>% roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% autoplot()
Nausea_aug1 %>% roc_auc(truth = Nausea, .pred_Yes, event_level = "second")

#Using the training data set
Nausea_aug2 = augment(Nausea_fit, training)
Nausea_aug2 %>% roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% autoplot()
Nausea_aug2 %>% roc_auc(truth = Nausea, .pred_Yes, event_level = "second")
```

After finding out the roc value of both which hovers around the 0.75 range, this means the model will be useful and possibly good.



## Workflow creation and Fitting for Main Outcome Runny Nose

We will repeat these steps but only using our main predictor which was runny nose. To do this the only difference we have to make is changing the recipe.

```{r repeat with just runny nose}
#Creating the recipe for nausea
Nausea_recipe2 = recipe(Nausea ~ RunnyNose, data = data)

#Creating a workflow that adds the model type and the recipe I previously made
Nausea_wrkflow2 <- workflow() %>% add_model(log_mod) %>% add_recipe(Nausea_recipe2)

#Creating a fit object
Nausea_fit2 <- Nausea_wrkflow2 %>% fit(data = training)

#Looking at the details of this fitted model
Nausea_fit2 %>% extract_fit_parsnip() %>% tidy()
```

## Evaluating Model

Now that we have a fitted object, we will apply it to the test data and predict some values.

```{r predicting and roc}
#We are predicting the values from the test data set with our fitted model
predict(Nausea_fit2, test)

#This is also doing the same thing as the predict function but it is showing the prediction proportions at each observation
Nausea_aug3 = augment(Nausea_fit2, test)

#Fitting a roc curve and looking at the roc-auc to determine if the model is a good fit.
#Remember this is only using the runny nose main predictor

#Using the test data set
Nausea_aug3 %>% roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% autoplot()
Nausea_aug3 %>% roc_auc(truth = Nausea, .pred_Yes, event_level = "second")

#Using the training data set
Nausea_aug4 = augment(Nausea_fit2, training)
Nausea_aug4 %>% roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% autoplot()
Nausea_aug4 %>% roc_auc(truth = Nausea, .pred_Yes, event_level = "second")
```

We can see that if we only use runny nose as our predictor, the roc has a value around 0.5 which mean the model is not a good fit. 

########################################################################
########################################################################

### Continious Outcome Additions

__Monica Chan: START__

Add a code that repeats the previous steps, but fits linear models to the continuous outcome.

1. All predictors: BodyTemp and all predictors
2. Just the main predictors: BodyTemp and RunnyNose

NOTE: change metric. RMSE

#### Data reminder
Data objects to start with:
```{r data reminder}
split_data #data split in a proportion of 1/4 test and 3/4 training.
#Assigned data sets from the split_data
glimpse(training)
glimpse(test)
```
#### Making a new recipe
```{r}
#Creating the recipe for continuous outcome (BodyTemp)
BT_recipe <- recipe(BodyTemp ~ ., data = data)
```
Adjusting NEW model for continuous outcome?
```{r new model}
#making a path for the regression model
lm_mod <- linear_reg() %>% 
  set_engine("lm")

lm_mod%>%
  parameters()
```
Adjusting workflow for the model working with continuous outcome Body Temp
```{r}
#Creating a workflow that adds the model type and the recipe
BT_wrkflow <- workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(BT_recipe)

#Creating a fit object
BT_fit <- BT_wrkflow %>% fit(data = training)

#Looking at the details of this fitted model
BT_fit %>% extract_fit_parsnip() %>% tidy()
```

Now that we have a fitted object, we will apply it to the test data and predict some values.

```{r predicting}
#Showing the prediction proportions at each observation
BT_aug1 <-augment(BT_fit, test)
```
#### Using the Root-mean square error (RMSE) to evaluate model fitness.
```{r}

#Using the test data set
BT_aug1 %>% rmse(truth = BodyTemp, .pred)

#Using the training data set
BT_aug2 = augment(BT_fit, training) #updated model for training
BT_aug2 %>% rmse(truth = BodyTemp, .pred)
```
RMSE using test data is estimated at 1.16
RMSE using training data is estimated at 1.11

### Fitting linear model between BodyTemp and Runny Nose
#### Making a new recipe
```{r}
#Creating the recipe for BodyTemp and Runny Nose
BT.RN_recipe <- recipe(BodyTemp ~ RunnyNose, data = data)
```
We're using the same linear regression model made above as lm_mod

```{r}
#Creating a workflow that adds the model type and the recipe I previously made
BT.RN_wrkflow <- workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(BT.RN_recipe)

#Creating a fit object
BT.RN_fit <- BT.RN_wrkflow %>% 
  fit(data = training)

#Looking at the details of this fitted model
BT.RN_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
```

Now that we have a fitted object, we will apply it to the test data and predict some values.


```{r}
#Same as predict function but shows the prediction proportions at each observation
BT.RN_aug = augment(BT.RN_fit, test)

#Fitting a roc curve and looking at the roc-auc to determine if the model is a good fit.
#Remember this is only using the runny nose main predictor

#Using the test data set
BT.RN_aug %>% rmse(truth = BodyTemp, .pred)

#Using the training data set
BT.RN_aug2 = augment(BT.RN_fit, training)
BT.RN_aug2 %>% rmse(truth = BodyTemp, .pred)
```
RMSE is estimated as 1.08 for the test data model.
RMSE is estimated 1.22 for the training data model.

#### Summary

The Root Mean Square Error (RMSE) assess how well a regression model fits a dataset by telling us the average distance between the predicted values from the model and actual values in the dataset. The lower the RMSE the better a given model is able to fit.

When comparing the model using the test data we see that the RMSE is lower when the predictor is limited to one value (RunnyNose, 1.08) compared to when all symptoms are used as predictors (All symptoms, 1.16). 
The opposite is true when using the training data (RunnyNose, 1.22; All symptoms, 1.11). 
The data suggests that the linear regression model for Body Temperature with the single predictor (symptoms of a runny nose) is better than the model using all symptoms as predictors.
This seems counter to what we would assume would make a "good" model. When thought through further the RMSE value is only about "fit" and having many predictors causes more complications to fit than a single variable.
Regardless, the estimates are very close with a difference of only 0.08. This suggests that there may be little difference between these linear models.

